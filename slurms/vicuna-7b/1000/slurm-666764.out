11/16/2023 14:37:43 - INFO - __main__ -   Args are parsed. And as follow: 
 model_name: vicuna-7b
device: cuda
file_path: /mnt/rstor/CSE_CSDS_VXC204/sxz517/mh_model_edit/code/
seed: 100
subquestion_breakdown: True
fact_retrieve: True
cot_contradiction: False
output_dir: /mnt/rstor/CSE_CSDS_VXC204/sxz517/mh_model_edit/output/
delete_duplicate_output_file: True
start: 0
end: 3000
fact_query_on: subquestion
edit_num: 1000
holistic_cot: False
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.25s/it]
11/16/2023 14:38:32 - INFO - __main__ -   Files are read and ready to be used!
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:00<00:24,  1.44it/s] 25%|██▌       | 9/36 [00:00<00:01, 14.60it/s] 47%|████▋     | 17/36 [00:00<00:00, 27.10it/s] 69%|██████▉   | 25/36 [00:01<00:00, 37.77it/s] 94%|█████████▍| 34/36 [00:01<00:00, 48.38it/s]100%|██████████| 36/36 [00:01<00:00, 31.27it/s]
11/16/2023 14:38:35 - INFO - __main__ -   Prepare works are Done!
  0%|          | 0/3000 [00:00<?, ?it/s]11/16/2023 14:38:50 - INFO - __main__ -   0, 1
  0%|          | 1/3000 [00:15<12:58:45, 15.58s/it]11/16/2023 14:39:05 - INFO - __main__ -   0, 2
  0%|          | 2/3000 [00:30<12:25:31, 14.92s/it]11/16/2023 14:39:24 - INFO - __main__ -   0, 3
  0%|          | 3/3000 [00:49<14:09:57, 17.02s/it]11/16/2023 14:39:39 - INFO - __main__ -   0, 4
  0%|          | 4/3000 [01:04<13:23:30, 16.09s/it]11/16/2023 14:39:53 - INFO - __main__ -   0, 5
  0%|          | 5/3000 [01:18<12:54:03, 15.51s/it]11/16/2023 14:40:06 - INFO - __main__ -   0, 6
  0%|          | 6/3000 [01:31<12:06:15, 14.55s/it]11/16/2023 14:40:19 - INFO - __main__ -   0, 7
  0%|          | 7/3000 [01:44<11:45:15, 14.14s/it]11/16/2023 14:40:32 - INFO - __main__ -   0, 8
  0%|          | 8/3000 [01:57<11:27:44, 13.79s/it]11/16/2023 14:40:47 - INFO - __main__ -   0, 9
  0%|          | 9/3000 [02:12<11:37:10, 13.99s/it]11/16/2023 14:40:56 - INFO - __main__ -   0, 10
  0%|          | 10/3000 [02:21<10:18:46, 12.42s/it]11/16/2023 14:41:12 - INFO - __main__ -   1, 11
  0%|          | 11/3000 [02:37<11:12:33, 13.50s/it]11/16/2023 14:41:27 - INFO - __main__ -   1, 12
  0%|          | 12/3000 [02:51<11:31:59, 13.90s/it]11/16/2023 14:41:33 - INFO - __main__ -   2, 13
  0%|          | 13/3000 [02:57<9:34:38, 11.54s/it] 11/16/2023 14:41:47 - INFO - __main__ -   2, 14
  0%|          | 14/3000 [03:12<10:13:15, 12.32s/it]11/16/2023 14:42:01 - INFO - __main__ -   2, 15
  0%|          | 15/3000 [03:26<10:42:29, 12.91s/it]11/16/2023 14:42:17 - INFO - __main__ -   2, 16
  1%|          | 16/3000 [03:42<11:28:43, 13.85s/it]11/16/2023 14:42:27 - INFO - __main__ -   2, 17
  1%|          | 17/3000 [03:52<10:36:31, 12.80s/it]11/16/2023 14:42:33 - INFO - __main__ -   3, 18
  1%|          | 18/3000 [03:58<8:45:55, 10.58s/it] 11/16/2023 14:42:49 - INFO - __main__ -   3, 19
  1%|          | 19/3000 [04:13<10:02:05, 12.12s/it]11/16/2023 14:43:06 - INFO - __main__ -   3, 20
  1%|          | 20/3000 [04:30<11:14:41, 13.58s/it]11/16/2023 14:43:20 - INFO - __main__ -   3, 21
  1%|          | 21/3000 [04:45<11:23:58, 13.78s/it]11/16/2023 14:43:29 - INFO - __main__ -   3, 22
  1%|          | 22/3000 [04:54<10:19:00, 12.47s/it]11/16/2023 14:43:42 - INFO - __main__ -   3, 23
  1%|          | 23/3000 [05:07<10:22:06, 12.54s/it]11/16/2023 14:43:57 - INFO - __main__ -   3, 24
  1%|          | 24/3000 [05:21<10:52:27, 13.15s/it]11/16/2023 14:44:12 - INFO - __main__ -   3, 25
  1%|          | 25/3000 [05:37<11:31:31, 13.95s/it]11/16/2023 14:44:29 - INFO - __main__ -   3, 26
  1%|          | 26/3000 [05:53<12:06:08, 14.65s/it]11/16/2023 14:44:43 - INFO - __main__ -   3, 27
  1%|          | 27/3000 [06:08<12:05:37, 14.64s/it]11/16/2023 14:45:00 - INFO - __main__ -   3, 28
  1%|          | 28/3000 [06:25<12:43:06, 15.41s/it]11/16/2023 14:45:17 - INFO - __main__ -   3, 29
  1%|          | 29/3000 [06:41<12:55:08, 15.65s/it]11/16/2023 14:45:31 - INFO - __main__ -   3, 30
  1%|          | 30/3000 [06:56<12:37:15, 15.30s/it]11/16/2023 14:45:47 - INFO - __main__ -   4, 31
  1%|          | 31/3000 [07:11<12:41:28, 15.39s/it]11/16/2023 14:46:06 - INFO - __main__ -   4, 32
  1%|          | 32/3000 [07:31<13:39:16, 16.56s/it]11/16/2023 14:46:18 - INFO - __main__ -   4, 33
  1%|          | 33/3000 [07:43<12:34:48, 15.26s/it]11/16/2023 14:46:31 - INFO - __main__ -   4, 34
  1%|          | 34/3000 [07:56<11:58:03, 14.53s/it]11/16/2023 14:46:44 - INFO - __main__ -   4, 35
  1%|          | 35/3000 [08:08<11:30:03, 13.96s/it]11/16/2023 14:47:00 - INFO - __main__ -   5, 36
  1%|          | 36/3000 [08:24<11:59:00, 14.55s/it]11/16/2023 14:47:12 - INFO - __main__ -   5, 37
  1%|          | 37/3000 [08:36<11:18:45, 13.74s/it]11/16/2023 14:47:29 - INFO - __main__ -   5, 38
  1%|▏         | 38/3000 [08:54<12:17:35, 14.94s/it]11/16/2023 14:47:48 - INFO - __main__ -   5, 39
  1%|▏         | 39/3000 [09:13<13:13:06, 16.07s/it]11/16/2023 14:48:02 - INFO - __main__ -   5, 40
  1%|▏         | 40/3000 [09:27<12:46:34, 15.54s/it]11/16/2023 14:48:15 - INFO - __main__ -   5, 41
  1%|▏         | 41/3000 [09:40<12:01:43, 14.63s/it]slurmstepd: error: *** JOB 666764 ON aisct04 CANCELLED AT 2023-11-16T14:48:21 ***
